{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de bibliotecas.\n",
    "\n",
    "import pandas as pd\n",
    "from inline_sql import sql, sql_val\n",
    "from pandasql import sqldf\n",
    "\n",
    "# Carga de datasets necesarios.\n",
    "\n",
    "Sedes = pd.read_csv('Tablas/Sedes.csv')\n",
    "Secciones = pd.read_csv('Tablas/Secciones.csv')\n",
    "Migrantes = pd.read_csv('Tablas/Migrantes.csv')\n",
    "Redes_Sociales_DB = pd.read_csv('Tablas/Redes_Sociales.csv')\n",
    "\n",
    "#Sedes[['id_sede', 'redes_sociales']]\n",
    "\n",
    "Redes_FB = [] # Facebook.\n",
    "Redes_TW = [] # Twitter.\n",
    "Redes_IG = [] # Instragram.\n",
    "Redes_YT = [] # YouTube.\n",
    "Redes_LI = [] # Linkedin.\n",
    "Redes_FR = [] # Flickr.\n",
    "Redes_Invalidas = [] # Links mal formados o @ ambiguos (Instagram o Twitter).\n",
    "Redes_NULL = [] # Sede sin link.\n",
    "\n",
    "Redes_Totales = [] # Redes totales.\n",
    "\n",
    "for Sede_Id, URL in zip(Redes_Sociales_DB['id_sede'], Redes_Sociales_DB['URL']):\n",
    "    URL_Lista = str(URL).split('  //  ') # Lista con las redes sociales de esa sede (puede estar vacía).\n",
    "\n",
    "    for URL in URL_Lista:\n",
    "\n",
    "        # Por el formato, si hay links el strip introduce un dato extra que siempre es el string vacío. Con esto, lo eliminamos.\n",
    "        if(URL == ''): continue \n",
    "\n",
    "        URL = URL.strip() # Quitar espacios al inicio y al final.\n",
    "        URL = URL.lower() # Que empiece siempre en minúscula para mayor consistencia (hay datos que se escapaban a esto y se filtraban mal).\n",
    "        \n",
    "        if(URL == 'nan'):\n",
    "            Redes_NULL.append(Sede_Id)   # Sedes sin redes.\n",
    "            continue\n",
    "        else: \n",
    "            Redes_Totales.append((Sede_Id, URL))  # Sedes con redes.\n",
    "\n",
    "        # Clasificar redes en distintas listas.\n",
    "        if(URL[0] =='@' or ' ' in URL or \".com\" not in URL): \n",
    "            Redes_Invalidas.append((Sede_Id, URL))\n",
    "        elif 'facebook' in URL: \n",
    "            Redes_FB.append((Sede_Id, URL))\n",
    "        elif('twitter' in URL): \n",
    "            Redes_TW.append((Sede_Id, URL))\n",
    "        elif('instagram' in URL): \n",
    "            Redes_IG.append((Sede_Id, URL))\n",
    "        elif('linkedin' in URL): \n",
    "            Redes_LI.append((Sede_Id, URL))\n",
    "        elif('flickr' in URL): \n",
    "            Redes_FR.append((Sede_Id, URL))\n",
    "        elif('youtube' in URL): \n",
    "            Redes_YT.append((Sede_Id, URL))\n",
    "\n",
    "# Redes a almacenar.\n",
    "Redes_Validas = Redes_FB + Redes_TW + Redes_IG + Redes_LI + Redes_FR + Redes_YT\n",
    "\n",
    "# Redes que no se usan.\n",
    "Redes_Descartadas = set(Redes_Totales).difference(set(Redes_FB)).difference(set(Redes_IG)).difference(set(Redes_LI)).difference(set(Redes_FR)).difference(set(Redes_YT)).difference(set(Redes_TW)).difference(set(Redes_Invalidas))\n",
    "\n",
    "# Creación de listas de almacenamiento.\n",
    "Sede_IDs = []\n",
    "Redes_Sociales = []\n",
    "URLs = []\n",
    "\n",
    "# Creación de diccionario vacío.\n",
    "Dic_Redes = {'id_sede': Sede_IDs, 'red_social': Redes_Sociales, 'url': URLs}\n",
    "\n",
    "# Relleno del diccionario con el id_sede, red_social y url.\n",
    "for Sede_Id, Url in Redes_FB:\n",
    "    Dic_Redes['id_sede'].append(Sede_Id)\n",
    "    Dic_Redes['red_social'].append('facebook')\n",
    "    Dic_Redes['url'].append(Url)\n",
    "\n",
    "for Sede_Id, Url in Redes_TW:\n",
    "    Dic_Redes['id_sede'].append(Sede_Id)\n",
    "    Dic_Redes['red_social'].append('twitter')\n",
    "    Dic_Redes['url'].append(Url)\n",
    "\n",
    "for Sede_Id, Url in Redes_IG:\n",
    "    Dic_Redes['id_sede'].append(Sede_Id)\n",
    "    Dic_Redes['red_social'].append('instagram')\n",
    "    Dic_Redes['url'].append(Url)\n",
    "\n",
    "for Sede_Id, Url in Redes_YT:\n",
    "    Dic_Redes['id_sede'].append(Sede_Id)\n",
    "    Dic_Redes['red_social'].append('youtube')\n",
    "    Dic_Redes['url'].append(Url)\n",
    "\n",
    "for Sede_Id, Url in Redes_FR:\n",
    "    Dic_Redes['id_sede'].append(Sede_Id)\n",
    "    Dic_Redes['red_social'].append('flickr')\n",
    "    Dic_Redes['url'].append(Url)\n",
    "\n",
    "for Sede_Id, Url in Redes_LI:\n",
    "    Dic_Redes['id_sede'].append(Sede_Id)\n",
    "    Dic_Redes['red_social'].append('linkedin')\n",
    "    Dic_Redes['url'].append(Url)\n",
    "\n",
    "# Formar df con el diccionario.\n",
    "Redes_DF = pd.DataFrame(Dic_Redes)\n",
    "\n",
    "# Consulta SQL.\n",
    "Query =  '''\n",
    "          SELECT s.nombre AS pais,\n",
    "                 r.id_sede AS sede,\n",
    "                 r.\"red_social\",\n",
    "                 r.url\n",
    "          FROM Redes_DF AS r\n",
    "          INNER JOIN Sedes AS s ON s.id_sede = r.id_sede\n",
    "          ORDER BY pais ASC, sede ASC, \"red_social\" ASC, url ASC\n",
    "'''\n",
    "\n",
    "Tabla = sqldf(Query)\n",
    "\n",
    "# Guardar archivo.\n",
    "Tabla.to_csv('Tablas/h.iv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
